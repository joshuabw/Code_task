{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e34fd3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from tensorflow.keras.models import Sequential, model_from_json\n",
    "from keras.layers import Dense, Input\n",
    "from keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39e65f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#file path retrieve\n",
    "data_dir = Path('/Users/joshua/chest_xray/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0db079e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = data_dir.glob('train/NORMAL/*.jpeg')\n",
    "p_train = data_dir.glob('train/PNEUMONIA/*.jpeg')\n",
    "n_test = data_dir.glob('test/NORMAL/*.jpeg')\n",
    "p_test = data_dir.glob('test/PNEUMONIA/*.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21b071b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_df(norm,pneu):\n",
    "    data = []\n",
    "    for img in norm:\n",
    "        data.append((str(img),0))\n",
    "    for img in pneu:\n",
    "        data.append((str(img),1))\n",
    "    data = pd.DataFrame(data, columns=['filepath', 'label'],index=None)\n",
    "    # shuffle data\n",
    "    data = data.sample(frac=1.).reset_index(drop=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1664a3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data_to_df(n_train,p_train)\n",
    "test_data = data_to_df(n_test,p_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d796878",
   "metadata": {},
   "outputs": [],
   "source": [
    "def case_count(data):\n",
    "    data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "108f60ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "case_count(train_data)\n",
    "#pneumonia    3875\n",
    "#normal    1341"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf05557",
   "metadata": {},
   "source": [
    "Inbalanced train_data: \n",
    "\n",
    "normal count: 1341\n",
    "\n",
    "pneumonia count: 3875"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72d56c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a dataframe of normal images for data augmentation\n",
    "norm_train = train_data[train_data['label']==0]\n",
    "norm_train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c43ecb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the image size to 160\n",
    "image_size = 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94538719",
   "metadata": {},
   "outputs": [],
   "source": [
    "#double the normal count by flip the image left and right/up and down\n",
    "def data_augmentation(dataset):\n",
    "    data = []\n",
    "    for i in range(len(dataset)):\n",
    "        image = cv2.imread(dataset['filepath'][i])\n",
    "        image_1 = tf.image.flip_left_right(image)\n",
    "        image_2 = tf.image.flip_up_down(image)\n",
    "        image_1 = asarray(image_1)\n",
    "        image_2 = asarray(image_2)\n",
    "        image_1 = cv2.resize(image_1, (image_size, image_size))\n",
    "        image_1 = np.dstack([image_1, image_1, image_1])\n",
    "        image_2 = cv2.resize(image_2, (image_size, image_size))\n",
    "        image_2 = np.dstack([image_2, image_2, image_2])\n",
    "        data.append([image_1, 0])\n",
    "        data.append([image_2, 0])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96db35ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-17 22:51:46.094244: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "data_aug = data_augmentation(norm_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb6fb50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data preprocessing\n",
    "def data_preprocess(dataset):\n",
    "    data = []\n",
    "    for i in range(len(dataset)):\n",
    "        image = cv2.imread(dataset['filepath'][i])\n",
    "        image = cv2.resize(image, (image_size, image_size))\n",
    "        image = np.dstack([image, image, image])\n",
    "        data.append([image, dataset['label'][i]])\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f69d094",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data_preprocess(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86ad6569",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add augmented normal images to training dataset\n",
    "train = train + data_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e31bf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separating the images and labels\n",
    "def separate(dataset):\n",
    "    img = []\n",
    "    label = []\n",
    "    for i in dataset:\n",
    "        img.append(i[0])\n",
    "        label.append(i[1])\n",
    "    img = np.array(img)\n",
    "    label = np.array(label)\n",
    "    #dataset[0] for image, dataset[1] for labels\n",
    "    return img,label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "794489d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = separate(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c3b05e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make model for prediction\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(image_size, image_size, 9)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    tf.keras.layers.Conv2D(filters=256, kernel_size=(3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(9, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10486102",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e8c56e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "79/79 [==============================] - 123s 2s/step - loss: 0.0196 - accuracy: 0.9924\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 122s 2s/step - loss: 0.0119 - accuracy: 0.9958\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 123s 2s/step - loss: 0.0079 - accuracy: 0.9976\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 122s 2s/step - loss: 0.0056 - accuracy: 0.9986\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 141s 2s/step - loss: 0.0034 - accuracy: 0.9994\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 142s 2s/step - loss: 0.0025 - accuracy: 0.9995\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 140s 2s/step - loss: 0.0014 - accuracy: 0.9997\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 141s 2s/step - loss: 8.6260e-04 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 140s 2s/step - loss: 5.7778e-04 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 142s 2s/step - loss: 4.2176e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13fde7be0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataset[0] for image, dataset[1] for labels\n",
    "model.fit(training[0], training[1], epochs=10, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a430c41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 3s 128ms/step - loss: 2.8791 - accuracy: 0.7628\n",
      "20/20 [==============================] - 3s 125ms/step\n"
     ]
    }
   ],
   "source": [
    "#test data preprocessing\n",
    "test = data_preprocess(test_data)\n",
    "testing = separate(test)\n",
    "#dataset[0] for image, dataset[1] for labels\n",
    "model.evaluate(testing[0], testing[1])\n",
    "preds = model.predict(testing[0], batch_size=32)\n",
    "preds = np.argmax(preds, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8bf62a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#configure confusion matrix for test data\n",
    "cm  = confusion_matrix(testing[1], preds)\n",
    "plot_confusion_matrix(cm,figsize=(15,8), hide_ticks=True,cmap=plt.cm.YlOrRd)\n",
    "plt.xticks(range(2), ['Normal', 'Pneumonia'], fontsize=15)\n",
    "plt.yticks(range(2), ['Normal', 'Pneumonia'], fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24590bd8",
   "metadata": {},
   "source": [
    "The test results show that the model predict 143 'normal' images wrongly to the pneumonia category (False positive). However only 3 images are wrongly categorized to normal when it's 'pneumonia'. \"its better to be healthy and falsely checked as pneumonia than having pneumonia and categorized as 'normal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d1b23d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 76.60 %\n",
      "Precision 0.73\n",
      "Recall 0.99\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = cm.ravel()\n",
    "#Accuracy\n",
    "Accuracy = (tn+tp)*100/(tp+tn+fp+fn)\n",
    "print(\"Accuracy {:0.2f} %\".format(Accuracy))\n",
    "\n",
    "#Precision\n",
    "Precision = tp/(tp+fp)\n",
    "print(\"Precision {:0.2f}\".format(Precision))\n",
    "\n",
    "#Recall \n",
    "Recall = tp/(tp+fn) \n",
    "print(\"Recall {:0.2f}\".format(Recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d528c24",
   "metadata": {},
   "source": [
    "Low testing accuracy possible cause: The training data is inbalanced with more 'pneumonia' image than 'normal', even though the data are augmented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a4a9aed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "#save model to json file for api to retrieve\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
